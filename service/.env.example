# Supabase Configuration
SUPABASE_URL=your_supabase_url_here
SUPABASE_KEY=your_supabase_anon_key_here

# AI Service API Keys
GEMINI_API_KEY=your_gemini_api_key_here
OPENAI_API_KEY=your_openai_api_key_here

# Per-Task LLM Configuration (format: provider:model)
# Available providers: gemini, openai
# Gemini models: gemini-2.5-flash (cost-effective, supports temperature control)
#                gemini-2.5-pro (higher quality, more expensive)
# OpenAI models: gpt-4o, gpt-4-turbo (support temperature)
# Note: GPT-5/o1 reasoning models do NOT support temperature parameter

# Using Gemini 2.5 Flash for all tasks (cost-effective with temperature control)
LLM_FEATURES=gemini:gemini-2.5-flash
LLM_INSIGHTS=gemini:gemini-2.5-flash
LLM_PATCH=gemini:gemini-2.5-flash
LLM_BRIEF=gemini:gemini-2.5-flash
LLM_ANALYZE=gemini:gemini-2.5-flash
LLM_EDIT=gemini:gemini-2.5-flash

# Debug settings
DEBUG_LLM=true
